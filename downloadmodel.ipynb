{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp39-cp39-win_amd64.whl (203.0 MB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\praty\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.1.2)\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\praty\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.12.2)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\praty\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.10.0 mpmath-1.3.0 networkx-3.2.1 sympy-1.13.1 torch-2.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe, torchfrtrace.exe and torchrun.exe are installed in 'c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.1.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\praty\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp39-none-win_amd64.whl (286 kB)\n",
      "Collecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.3-cp39-none-win_amd64.whl (2.4 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\praty\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (24.2)\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.11.6-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\praty\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\praty\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\praty\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, tqdm, requests, pyyaml, huggingface-hub, tokenizers, safetensors, regex, numpy, transformers\n",
      "Successfully installed certifi-2024.8.30 charset-normalizer-3.4.0 huggingface-hub-0.26.2 idna-3.10 numpy-2.0.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.4.5 tokenizers-0.20.3 tqdm-4.67.1 transformers-4.46.3 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.1.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'premise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m                       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-mnli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m classifier(\u001b[43mpremise\u001b[49m, hypothesis)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'premise' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# classifier = pipeline(\"zero-shot-classification\",\n",
    "#                       model=\"facebook/bart-large-mnli\")\n",
    "# classifier(premise, hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2869: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'We should always try to eat healthy',\n",
       " 'labels': ['food', 'cooking', 'travel', 'dancing'],\n",
       " 'scores': [0.924102783203125,\n",
       "  0.05158378928899765,\n",
       "  0.012863397598266602,\n",
       "  0.011450021527707577]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "\n",
    "device = \"cpu\"\n",
    "text = \"We should always try to eat healthy\"\n",
    "lables = ['travel', 'cooking', 'dancing','food']\n",
    "results = {\"lables\": [], \"score\" : []}\n",
    "\n",
    "for lable in lables:\n",
    "    hypothesis = f'This example is {lable}.'\n",
    "    # run through model pre-trained on MNLI\n",
    "    x = tokenizer.encode(text, hypothesis, return_tensors='pt',\n",
    "                        truncation_strategy='only_first')\n",
    "    model =nli_model(x.to(device))\n",
    "    logits = nli_model(x.to(device))[0]\n",
    "\n",
    "    # we throw away \"neutral\" (dim 1) and take the probability of\n",
    "    # \"entailment\" (2) as the probability of the label being true \n",
    "    entail_contradiction_logits = logits[:,[0,2]]\n",
    "    probs = entail_contradiction_logits.softmax(dim=1)\n",
    "    prob_label_is_true = probs[:,1]\n",
    "    results[\"lables\"].append(lable)\n",
    "    results[\"score\"].append(float(probs[:,1].detach().numpy()[0]))\n",
    "    \n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=nli_model, tokenizer=tokenizer)\n",
    "classifier(text, lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00018880754942074418,\n",
       " 0.17667818069458008,\n",
       " 0.001159883220680058,\n",
       " 0.9525015950202942]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(f\"D:/Study_Materials/model/text_classification/model/tokenizer\")\n",
    "nli_model.save_pretrained(f\"D:/Study_Materials/model/text_classification/model/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\praty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2869: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'We should always try to eat healthy',\n",
       " 'labels': ['food', 'cooking', 'travel', 'dancing'],\n",
       " 'scores': [0.924102783203125,\n",
       "  0.05158378928899765,\n",
       "  0.01286340318620205,\n",
       "  0.0114500243216753]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "mod = AutoModelForSequenceClassification.from_pretrained('D:/Study_Materials/model/text_classification/model/tokenizer')\n",
    "tok = AutoTokenizer.from_pretrained('D:/Study_Materials/model/text_classification/model/tokenizer')\n",
    "\n",
    "device = \"cpu\"\n",
    "text = \"We should always try to eat healthy\"\n",
    "lables = ['travel', 'cooking', 'dancing','food']\n",
    "results = {\"lables\": [], \"score\" : []}\n",
    "\n",
    "for lable in lables:\n",
    "    hypothesis = f'This example is {lable}.'\n",
    "    # run through model pre-trained on MNLI\n",
    "    x = tok.encode(text, hypothesis, return_tensors='pt',\n",
    "                        truncation_strategy='only_first')\n",
    "    model =mod(x.to(device))\n",
    "    logits = mod(x.to(device))[0]\n",
    "\n",
    "    # we throw away \"neutral\" (dim 1) and take the probability of\n",
    "    # \"entailment\" (2) as the probability of the label being true \n",
    "    entail_contradiction_logits = logits[:,[0,2]]\n",
    "    probs = entail_contradiction_logits.softmax(dim=1)\n",
    "    prob_label_is_true = probs[:,1]\n",
    "    results[\"lables\"].append(lable)\n",
    "    results[\"score\"].append(float(probs[:,1].detach().numpy()[0]))\n",
    "    \n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=mod, tokenizer=tok)\n",
    "classifier(text, lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lables': ['travel', 'cooking', 'dancing', 'food'],\n",
       " 'score': [0.00018880754942074418,\n",
       "  0.1766781508922577,\n",
       "  0.0011598836863413453,\n",
       "  0.9525015950202942]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
